import os
import argparse
import whisper
import torch

from tqdm import tqdm
import sys
import os



from common.constants import Languages
from common.log import logger
from common.stdout_wrapper import SAFE_STDOUT

import re


device = "cuda:0" if torch.cuda.is_available() else "cpu"


from funasr import AutoModel

model_dir = "iic/SenseVoiceSmall"


emo_dict = {
	"<|HAPPY|>": "ğŸ˜Š",
	"<|SAD|>": "ğŸ˜”",
	"<|ANGRY|>": "ğŸ˜¡",
	"<|NEUTRAL|>": "",
	"<|FEARFUL|>": "ğŸ˜°",
	"<|DISGUSTED|>": "ğŸ¤¢",
	"<|SURPRISED|>": "ğŸ˜®",
}

event_dict = {
	"<|BGM|>": "ğŸ¼",
	"<|Speech|>": "",
	"<|Applause|>": "ğŸ‘",
	"<|Laughter|>": "ğŸ˜€",
	"<|Cry|>": "ğŸ˜­",
	"<|Sneeze|>": "ğŸ¤§",
	"<|Breath|>": "",
	"<|Cough|>": "ğŸ¤§",
}

emoji_dict = {
	"<|nospeech|><|Event_UNK|>": "â“",
	"<|zh|>": "",
	"<|en|>": "",
	"<|yue|>": "",
	"<|ja|>": "",
	"<|ko|>": "",
	"<|nospeech|>": "",
	"<|HAPPY|>": "ğŸ˜Š",
	"<|SAD|>": "ğŸ˜”",
	"<|ANGRY|>": "ğŸ˜¡",
	"<|NEUTRAL|>": "",
	"<|BGM|>": "ğŸ¼",
	"<|Speech|>": "",
	"<|Applause|>": "ğŸ‘",
	"<|Laughter|>": "ğŸ˜€",
	"<|FEARFUL|>": "ğŸ˜°",
	"<|DISGUSTED|>": "ğŸ¤¢",
	"<|SURPRISED|>": "ğŸ˜®",
	"<|Cry|>": "ğŸ˜­",
	"<|EMO_UNKNOWN|>": "",
	"<|Sneeze|>": "ğŸ¤§",
	"<|Breath|>": "",
	"<|Cough|>": "ğŸ˜·",
	"<|Sing|>": "",
	"<|Speech_Noise|>": "",
	"<|withitn|>": "",
	"<|woitn|>": "",
	"<|GBG|>": "",
	"<|Event_UNK|>": "",
}

lang_dict =  {
    "<|zh|>": "<|lang|>",
    "<|en|>": "<|lang|>",
    "<|yue|>": "<|lang|>",
    "<|ja|>": "<|lang|>",
    "<|ko|>": "<|lang|>",
    "<|nospeech|>": "<|lang|>",
}

emo_set = {"ğŸ˜Š", "ğŸ˜”", "ğŸ˜¡", "ğŸ˜°", "ğŸ¤¢", "ğŸ˜®"}
event_set = {"ğŸ¼", "ğŸ‘", "ğŸ˜€", "ğŸ˜­", "ğŸ¤§", "ğŸ˜·",}

lang2token = {
            'zh': "ZH|",
            'ja': "JP|",
            "en": "EN|",
            "ko": "KO|",
            "yue": "YUE|",
        }

def format_str(s):
	for sptk in emoji_dict:
		s = s.replace(sptk, emoji_dict[sptk])
	return s


def format_str_v2(s):
	sptk_dict = {}
	for sptk in emoji_dict:
		sptk_dict[sptk] = s.count(sptk)
		s = s.replace(sptk, "")
	emo = "<|NEUTRAL|>"
	for e in emo_dict:
		if sptk_dict[e] > sptk_dict[emo]:
			emo = e
	for e in event_dict:
		if sptk_dict[e] > 0:
			s = event_dict[e] + s
	s = s + emo_dict[emo]

	for emoji in emo_set.union(event_set):
		s = s.replace(" " + emoji, emoji)
		s = s.replace(emoji + " ", emoji)
	return s.strip()

def format_str_v3(s):
	def get_emo(s):
		return s[-1] if s[-1] in emo_set else None
	def get_event(s):
		return s[0] if s[0] in event_set else None

	s = s.replace("<|nospeech|><|Event_UNK|>", "â“")
	for lang in lang_dict:
		s = s.replace(lang, "<|lang|>")
	s_list = [format_str_v2(s_i).strip(" ") for s_i in s.split("<|lang|>")]
	new_s = " " + s_list[0]
	cur_ent_event = get_event(new_s)
	for i in range(1, len(s_list)):
		if len(s_list[i]) == 0:
			continue
		if get_event(s_list[i]) == cur_ent_event and get_event(s_list[i]) != None:
			s_list[i] = s_list[i][1:]
		#else:
		cur_ent_event = get_event(s_list[i])
		if get_emo(s_list[i]) != None and get_emo(s_list[i]) == get_emo(new_s):
			new_s = new_s[:-1]
		new_s += s_list[i].strip().lstrip()
	new_s = new_s.replace("The.", " ")
	return new_s.strip()

def transcribe_one(audio_path,language):

    model = AutoModel(model=model_dir,
                  vad_model="fsmn-vad",
                  vad_kwargs={"max_single_segment_time": 30000},
                  trust_remote_code=True, device="cuda:0")

    res = model.generate(
        input=audio_path,
        cache={},
        language=language, # "zn", "en", "yue", "ja", "ko", "nospeech"
        use_itn=False,
        batch_size_s=0, 
    )

    try:

        text = res[0]["text"]
        text = format_str_v3(text)
        print(text)
    except Exception as e:
        print(e)
        text = ""


    return text,language


if __name__ == "__main__":

    parser = argparse.ArgumentParser()

    parser.add_argument(
        "--language", type=str, default="ja", choices=["ja", "en", "zh","yue","ko"]
    )
    parser.add_argument("--model_name", type=str, required=True)


    parser.add_argument("--input_file", type=str, default="./wavs/")

    parser.add_argument("--file_pos", type=str, default="")
    

    args = parser.parse_args()

    speaker_name = args.model_name

    language = args.language


    input_file = args.input_file

    if input_file == "":
        input_file = "./wavs/"

    file_pos = args.file_pos


    wav_files = [
        f for f in os.listdir(f"{input_file}") if f.endswith(".wav")
    ]


    with open("./esd.list", "w", encoding="utf-8") as f:
        for wav_file in tqdm(wav_files, file=SAFE_STDOUT):
            file_name = os.path.basename(wav_file)
            
            text,lang = transcribe_one(f"{input_file}"+wav_file,language)

            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–'deedee'
            match = re.search(r'(^.*?)_.*?(\..*?$)', wav_file)
            if match:
                extracted_name = match.group(1) + match.group(2)
            else:
                print("No match found")
                extracted_name = "sample"

            if lang == "ja":
                language_id = "JA"
            elif lang == "en":
                language_id = "EN"
            elif lang == "zh":
                language_id = "ZH"
            elif lang == "yue":
                language_id = "YUE"
            elif lang == "ko":
                language_id = "KO"

            f.write(file_pos+f"{file_name}|{extracted_name.replace('.wav','')}|{language_id}|{text}\n")

            f.flush()
    sys.exit(0)


